 This discrep- ancy highlights a tradeoff in study design: phone surveys, while usually cheaper, generate noisier data. The standard error approximation in (2) provides a straightforward quantification of this tradeoff. To estimate the effect of treatment on pigeon pea production with equal precision, the phone survey would have needed to be 10.7 times larger than the in-person survey; 1.2 times for lentils; 3.1 times for green peas; and 1.8 times larger for fava beans. That is, the cost per response may need to be up to 10.7 times lower over the phone than in person, depending on the outcome of interest, for phone surveying to be a cost-effective method to improve study power. Estimates in Fig. 4 control for household fixed characteristics elicited in person at midline. Dropping these covariates lowers precision, but point estimates remain stable and the relative difference in standard er- rors persists. This same pattern of consistent point estimates but larger standard errors in phone survey data also appears when restricting to the overlapping subsample9 of households that participated in both 8 Survey mode may still play a role in the interpretation of outcomes if treatment effects are benchmarked against the control mean or reported in standardized units. 9 The in-person sampling frame included households that reported zero area planted at midline, but these households were excluded from phone surveying. To recover consistent treatment effects for this exercise, we supplement the overlapping sample with all zero-area households that were selected for in-person surveying, weighted by the phone-survey attrition rate as before. surveys. The implied cost ratio in these specifications leans slightly more in favor of in-person surveying. 5. Conclusion Overall, this study uncovers meaningful differences in the sample distribution of agricultural output across survey modes. We show a systematic pattern of higher self-reported production over the phone relative to in person, even within the same respondent, which may bias estimates of local or regional productivity. It remains an open question which mode more closely approximates the truth. Validat- ing survey-based production measures would require more resource- intensive methods such as sub-plot crop cuts or monitoring of full plot harvests (see Lobell et al., 2020; Kosmowski et al., 2021), and such validation is beyond the scope of this study. The discrepancy between survey modes is consistent with greater social desirability bias among phone respondents. Surveys were part of an initiative to increase pulse production, a goal well understood by both treatment and control farmers, and the survey mode effect is most apparent among the two crops explicitly promoted by the intervention. Evidence of social desirability bias among phone sur- vey respondents, possibly related to enumeratorsâ€™ inability to verify responses, has previously been found in studies of agricultural pro- ductivity (Kilic et al.