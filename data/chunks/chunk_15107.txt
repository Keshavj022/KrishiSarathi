, 2021), student performance (Crawfurd et al., 2021), political attitudes (Holbrook et al., 2003), and urban microen- trepreneurship (Garlick et al., 2020). The former three settings produce similar evidence that phone surveys generate more socially desirable population outcomes. Among urban microentrepreneurs, this bias man- ifests in self-reported data reliability – whether respondents claim to keep written records – but not in business outcomes, which may be equally difficult to verify by phone and in person. Our findings more generally highlight a potential challenge in main- taining long-term databases such as those produced by national sta- tistical offices. Time-series population statistics may be disrupted as Journal of Development Economics 166 (2024) 103199 9 E. Anderson et al. survey units update procedures to take advantage of more pervasive in- formation and communication technologies. Improved aggregation and imputation methods have already proven to generate discontinuities in historical trends (Jerven, 2013). Survey-mode-induced disruptions may be more difficult to detect because they coincide with technological expansions that cause real deviations from trend, and will be especially obscured where new survey methods were adopted out of necessity during the COVID-19 pandemic. In such cases it will be imperative to design surveys that allow researchers to reconcile new and old data, and eliminate artifacts of the method of data collection. Somewhat reassuringly, survey mode effects appear to be less con- cerning for bias in program evaluation. Gaps in self-reported agricul- tural production are consistent across experimental study arms and therefore do not influence the magnitude of estimated program im- pacts. Data differences by survey mode are nevertheless important for research design due to precision. We report higher sampling variation in outcome data by phone, though the influence of this difference varies by outcome. In-person surveying at midline further improved precision by allowing us to control for household characteristics. If these covariates were measured more poorly or not at all by phone at midline, the gap in precision between survey modes would have been even greater. Overall, our results caution phone surveying may not save on costs if larger sample sizes are needed to achieve the same level of power. Implementation experience raises two additional research design considerations not directly quantified in this analysis. First, different survey modes may have different levels of success in reaching specific household members for participation. In our study, in-person enumer- ators reached the primary farmer slightly more frequently than phone surveyors. Relative success rates may vary across different contexts. Second, while we focus on the subset of outcomes elicited both in person and by phone, surveys also varied in the scope of their questionnaires.