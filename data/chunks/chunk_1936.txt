 Revolutionizing Agriculture: The Digital Transformation of Farming Technical Report Some commonly used models in predicting crop traits are listed below- Table 5: List of some commonly used models in predicting crop traits S. No. Algorithm Features 1. Kernel ridge Kernel is introduced to RR. Uses squared error loss. Faster regression (KRR) | for medium-sized datasets. Matrix inversion 2. Least squares Model the relationship between a dependent variable linear regression | and one or more independent variables. Does not (LSLR) consider the complexity of data. 3. Neural network | Approach that uses a _ standard back-propagation (NN) algorithm applied to a set of input, hidden, and output layers. Predicts the results for unknown datasets. Requires labelled data for the training process. The training of the network takes time. 4. Support vector | Works on the concept of maximizing the margins. regression (SVR) | Generates a decision boundary with maximum separation. Proves helpful when multiple heterogeneous classes are available. 5. Extreme learning | Learning algorithm for single-layered feed-forward neural machine (ELM) network. Fast learning. Computationally scalable. Independent from the tuning process. Evaluation speed is low. 6. Bagging trees General-purpose procedure for reducing the variance of (BaTs) a statistical learning method. Makes predictions on the treeâ€™s out-of-bag observations. Multiple trees can be trained simultaneously. All the trees trained on different bootstrap samples are correlated. 7. Boosting trees Transforms weak decision trees (called weak learners) (BoTs) into strong learners. Tends to overfit. Better than random predictions. Good at handling tabular data with numerical features. Able to capture nonlinear interactions between the features and the target. Not designed to work with very sparse features. 8. Random Forest | An ensemble approach uses decision trees. Creates multiple decision trees on different data samples and then predict the data from each subset. Finally the forest (group of random trees) is averaged. 9. Gaussian Process | Probabilistic (Bayesian) approach, An _ additional regression (GPR) | quantitative measurement of prediction accuracy in terms of uncertainty estimates, Use of kernels or covariance functions to reduce the processing time. TEC 31228:2024 Telecommunication Engineering Centre 30 Revolutionizing Agriculture: The Digital Transformation of Farming Technical Report TEC 31228:2024 Telecommunication Engineering Centre 31 10. Partial least square regression (PLSR) Combines the benefits of principal component analysis and multivariate linear regression by reducing data dimensionality, transformation, and regression 3.2.2 Deep Learning/ Artificial Neural Networks Deep Learning is the process of implementing neural networks on the high dimensional data to give insights and provide solutions.