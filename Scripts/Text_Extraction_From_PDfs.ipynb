{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qsIhLG-Vpbe9",
        "outputId": "781a0aea-136c-4e68-c32d-f6be4928649f"
      },
      "outputs": [],
      "source": [
        "!pip install pytesseract pdf2image Pillow pymupdf requests\n",
        "!sudo apt-get update\n",
        "!sudo apt-get install poppler-utils tesseract-ocr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UIkY4TiVLbti",
        "outputId": "1e5c08e3-0fc6-4f20-f438-9515511e0108"
      },
      "outputs": [],
      "source": [
        "!pip install spellchecker\n",
        "!pip install pyspellchecker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5ZGc_eAfk7m",
        "outputId": "818f279f-32f6-4940-eba2-db9528859096"
      },
      "outputs": [],
      "source": [
        "!pip install symspellpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gu1FhbhRL1zJ",
        "outputId": "9989b4db-0c29-408b-99ee-ef19473181e2"
      },
      "outputs": [],
      "source": [
        "import fitz\n",
        "import os\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "\n",
        "ROOT_DIR = \"ICAR DATA/\"\n",
        "OUTPUT_FILE = \"extracted_text.txt\"\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    text = \"\"\n",
        "    try:\n",
        "        doc = fitz.open(pdf_path)\n",
        "        for page in doc:\n",
        "            page_text = page.get_text(\"text\")\n",
        "            page_text = re.sub(r'\\n+', ' ', page_text)\n",
        "            page_text = re.sub(r'\\s+', ' ', page_text).strip()\n",
        "            page_text = re.sub(r'Page\\s*\\d+', '', page_text)\n",
        "            text += page_text + \" \"\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting {pdf_path}: {e}\")\n",
        "    return text\n",
        "\n",
        "all_text = \"\"\n",
        "pdf_files = []\n",
        "\n",
        "for root, _, files in os.walk(ROOT_DIR):\n",
        "    for file in files:\n",
        "        if file.endswith(\".pdf\"):\n",
        "            pdf_files.append(os.path.join(root, file))\n",
        "\n",
        "print(f\"Found {len(pdf_files)} PDFs. Extracting text...\")\n",
        "\n",
        "for pdf in tqdm(pdf_files):\n",
        "    all_text += extract_text_from_pdf(pdf) + \"\\n\\n\"\n",
        "\n",
        "with open(OUTPUT_FILE, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(all_text)\n",
        "\n",
        "print(f\"Extraction complete! Text saved in {OUTPUT_FILE}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNCigw9lfNky",
        "outputId": "10068a74-6345-4a84-8099-cc773ca108d1"
      },
      "outputs": [],
      "source": [
        "from symspellpy import SymSpell, Verbosity\n",
        "\n",
        "sym_spell = SymSpell()\n",
        "sym_spell.load_dictionary(\"/content/frequency_dictionary_en_82_765.txt\", term_index=0, count_index=1)\n",
        "\n",
        "def correct_spelling(text):\n",
        "    words = text.split()\n",
        "    corrected_words = []\n",
        "    for word in words:\n",
        "        suggestion = sym_spell.lookup(word, Verbosity.CLOSEST, max_edit_distance=2)\n",
        "        corrected_words.append(suggestion[0].term if suggestion else word)\n",
        "    return \" \".join(corrected_words)\n",
        "\n",
        "with open(OUTPUT_FILE, \"r\", encoding=\"utf-8\") as f:\n",
        "    extracted_text = f.read()\n",
        "\n",
        "cleaned_text = correct_spelling(extracted_text)\n",
        "\n",
        "with open(\"cleaned_text.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(cleaned_text)\n",
        "\n",
        "print(\"Spelling correction complete! Saved as cleaned_text.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9NezwD4f4NN",
        "outputId": "ba5431a9-b02a-4d79-f0f4-ba10332c07cf"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def clean_text(file_path, output_path):\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        text = f.read()\n",
        "    text = re.sub(r\"[*_#{}\\[\\]<>|]\", \"\", text)\n",
        "    text = re.sub(r\"[\\-–—]{2,}\", \" \", text)\n",
        "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
        "    text = re.sub(r\"\\n{2,}\", \"\\n\", text)\n",
        "\n",
        "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(text)\n",
        "\n",
        "    print(\"Text cleaned and saved to\", output_path)\n",
        "\n",
        "\n",
        "clean_text(\"cleaned_text.txt\", \"icar_extracted_text.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4FzVp9FrfzQc"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
